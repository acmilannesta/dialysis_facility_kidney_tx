{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facility_table3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDDlQCI6003-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "c9235cfd-4f96-4a99-cdea-0921a1c2c967"
      },
      "source": [
        "!pip install lifelines"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lifelines\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/1b/c6060bf7b89fc8a2e4b14cda99b0ccd778a9ea8c5c0a3baf6f7ef8433961/lifelines-0.21.1-py3-none-any.whl (322kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.2.1)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.16.3)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (0.24.2)\n",
            "Requirement already satisfied: bottleneck>=1.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.2.1)\n",
            "Requirement already satisfied: autograd>=1.2 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd>=1.2->lifelines) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=3.0->lifelines) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0->lifelines) (41.0.1)\n",
            "Installing collected packages: lifelines\n",
            "Successfully installed lifelines-0.21.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Rn5KMozIK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e295fbd-d619-4a6f-c144-24fd583144df"
      },
      "source": [
        "import pandas as pd, numpy as np, re\n",
        "from numpy import exp, mean\n",
        "from fancyimpute import IterativeImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lifelines import CoxPHFitter, AalenJohansenFitter\n",
        "# import statsmodels.api as sm\n",
        "# from matplotlib import pyplot as plt\n",
        "# from resample.bootstrap import bootstrap_ci, bootstrap"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqDzEmUndAN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "31c84939-195a-4424-e81d-d67f58285ab9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5wkW5xIwqs",
        "colab_type": "text"
      },
      "source": [
        "**Read data and restrict to first two years of follow-up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSOOxHrj28Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# whole cohort (N=1,478,506)\n",
        "d = pd.read_csv('Drive/My Drive/facility/Fortable3mi_ld_dec_censored.csv')\n",
        "d['rucc_rural'] = np.where(d.RUCC_2013.isin([1, 2, 3]), 0, (np.where(d.RUCC_2013.isna(), np.nan, 1)))\n",
        "d = d.drop(['RUCC_2013'], axis=1)\n",
        "# d.loc[d['wl_time']>24, 'wl']=0\n",
        "# d.loc[d['wl_time']>24, 'wl_time']=24\n",
        "# d.loc[d['ld_time']>24, 'livingd']=0\n",
        "# d.loc[d['ld_time']>24, 'ld_time']=24\n",
        "# d.loc[d['dec_time']>24, 'deceasedt']=0\n",
        "# d.loc[d['dec_time']>24, 'dec_time']=24\n",
        "# d.to_csv('drive/My Drive/facility/jama_round4.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1gt0guP4yEJ",
        "colab_type": "text"
      },
      "source": [
        "**Poisson model for table 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LnbwR3M44B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects.packages import importr\n",
        "from rpy2.robjects.vectors import FloatVector\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import rpy2.robjects.numpy2ri\n",
        "rpy2.robjects.numpy2ri.activate()\n",
        "from rpy2.robjects.packages import importr\n",
        "utils = importr('utils')\n",
        "utils.install_packages('msm')\n",
        "msm = importr('msm')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "danCnl1g4_1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "92c01c15-2636-4a70-82fc-00e36b428446"
      },
      "source": [
        "# Truncate follow-up time\n",
        "def truncate(t):\n",
        "    e = d.copy()\n",
        "    e.loc[e['wl_time'] > t, 'wl']=0\n",
        "    e.loc[e['wl_time'] > t, 'wl_time']=t\n",
        "    e.loc[e['ld_time'] > t, 'livingd']=0\n",
        "    e.loc[e['ld_time'] > t, 'ld_time']=t\n",
        "    e.loc[e['dec_time'] > t, 'deceasedt']=0\n",
        "    e.loc[e['dec_time'] > t, 'dec_time']=t\n",
        "    return e\n",
        "\n",
        "# dataset with aggregate sum for poisson model\n",
        "for event, time in zip(['wl','livingd', 'deceasedt'],['wl_time', 'ld_time', 'dec_time']):\n",
        "\tfor cutoff in [12, 36, 60]:\n",
        "\t\tpoissonset = truncate(cutoff).groupby(['for_profit', 'age_cat', 'sex_new', 'race_new'], as_index=False)[['wl', 'wl_time', 'livingd', 'ld_time', 'dec_time', 'deceasedt']].sum()\n",
        "\t\tpoissonset['age_cat'] = pd.Categorical(poissonset['age_cat'], ordered=True, categories=[5, 1, 2, 3, 4, 6])\n",
        "\t\tpoissonset['race_new'] = pd.Categorical(poissonset['race_new'], ordered=True, categories=[1, 2, 3, 4])\n",
        "\n",
        "\t\t# poisson regression\n",
        "\t\tpoisson_model = smf.glm(event+'~for_profit+sex_new+age_cat+race_new',\n",
        "\t\t\t\t\t\t\t\tdata=poissonset,\n",
        "\t\t\t\t\t\t\t\tfamily=sm.families.Poisson(),\n",
        "\t\t\t\t\t\t\t\toffset=np.log(poissonset[time]/12)).fit(method='newton')\n",
        "\n",
        "\t\t# extract coefficient\n",
        "\t\tb0 = poisson_model.params['Intercept']\n",
        "\t\tb1 = poisson_model.params['for_profit']\n",
        "\n",
        "\t\t# calculate rate difference and standard error\n",
        "\t\teffect = np.exp(b0 + b1) - np.exp(b0)\n",
        "\t\tvcov = poisson_model.cov_params().loc[['Intercept', 'for_profit'], ['Intercept', 'for_profit']]\n",
        "\t\tse = msm.deltamethod(ro.Formula('~exp(x1+x2)-exp(x1)'), FloatVector([b0, b1]), ro.r.matrix(vcov.values, nrow=2, ncol=2))\n",
        "\t\tprint(\"%s %g-months for_profit vs. non_profit: %.2f (%.2f, %.2f) \" %(event, cutoff, effect*100, (effect-1.96*float(np.array(se)))*100, (effect+1.96*float(np.array(se)))*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wl 12-months for_profit vs. non_profit: -9.62 (-9.89, -9.36) \n",
            "wl 36-months for_profit vs. non_profit: -6.75 (-6.90, -6.61) \n",
            "wl 60-months for_profit vs. non_profit: -5.38 (-5.49, -5.27) \n",
            "livingd 12-months for_profit vs. non_profit: -0.74 (-0.80, -0.67) \n",
            "livingd 36-months for_profit vs. non_profit: -0.76 (-0.80, -0.71) \n",
            "livingd 60-months for_profit vs. non_profit: -0.64 (-0.67, -0.60) \n",
            "deceasedt 12-months for_profit vs. non_profit: -0.23 (-0.26, -0.19) \n",
            "deceasedt 36-months for_profit vs. non_profit: -0.80 (-0.84, -0.75) \n",
            "deceasedt 60-months for_profit vs. non_profit: -1.08 (-1.13, -1.03) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXdvjdj8HyFG",
        "colab_type": "text"
      },
      "source": [
        "**Random forest imputation for categorical**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUn4sG8n1YpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for var in ['dialysis_mod1', 'insurance_esrd', 'rucc_rural', 'nephcare_cat2']:\n",
        "    pred = ['sex_new', 'age_cat', 'race_new', var]\n",
        "    imputer = IterativeImputer(n_iter=1, random_state=7, predictor=RandomForestClassifier(n_estimators=10))\n",
        "    imputed = pd.DataFrame(imputer.fit_transform(d[pred]), columns=pred)\n",
        "    d = d.drop(var, axis=1).join(imputed[var])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt27VI7ZH7Yi",
        "colab_type": "text"
      },
      "source": [
        "**Bayesian Ridge linear imputation for continuous**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZh15RQI1b31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for var in ['Hospitalization_Rate_facility', 'Mortality_Rate_Facility', 'NEAR_DIST']:\n",
        "    completed = []\n",
        "    for i in range(5):\n",
        "        pred = ['sex_new', 'age_cat', 'race_new', var]\n",
        "        imputer = IterativeImputer(n_iter=5, sample_posterior=True, random_state=i)\n",
        "        completed.append(imputer.fit_transform(d[pred]))\n",
        "    completed_mean = np.mean(completed, axis=0)\n",
        "    imputed = pd.DataFrame(completed_mean, columns=pred)\n",
        "    if var == 'NEAR_DIST':\n",
        "        m = imputed[imputed.NEAR_DIST > 0].NEAR_DIST.mean()\n",
        "        imputed.NEAR_DIST = np.where(imputed.NEAR_DIST < 0, m, imputed.NEAR_DIST)\n",
        "    d = d.drop(var, axis=1).join(imputed[var])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kH16VvFIJkD",
        "colab_type": "text"
      },
      "source": [
        "**Create cohort for Cox model**\n",
        "\n",
        "**1) dummy code and order levels based on table**\n",
        "\n",
        "**2) drop unneeded variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPTmCPR035rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standard cohort\n",
        "PH_data = d[['PROVUSRD', 'chain_class2', 'for_profit', 'sex_new', 'age_cat', 'race_new', 'dialysis_mod1', 'esrd_cause', 'bmi_35',\n",
        "                 'ashd_new', 'chf',\t'other_cardiac', 'cva_new',\t'pvasc_new', 'hypertension', 'diabetes', 'copd_new',\n",
        "                 'smoke_new', 'cancer_new', 'insurance_esrd', 'PATTXOP_MEDUNFITn','nephcare_cat2', 'profit_txc', 'profit_hosp',\n",
        "                 'network_us_region_dfr', 'NEAR_DIST', 'rucc_rural', 'wl', 'wl_time', 'livingd', 'ld_time', 'deceasedt', 'dec_time']]\n",
        "PH_data = PH_data.join(pd.get_dummies(PH_data.dialysis_mod1, prefix='dialysis_mod1', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(pd.Categorical(PH_data.insurance_esrd, [3, 2, 1, 4, 5], True), prefix='insurance_esrd', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(pd.Categorical(PH_data.age_cat, [5, 1, 2, 3, 4, 6], True), prefix='age_cat', drop_first=True)) # delete category \"6\" for ideal cohort!\n",
        "PH_data = PH_data.join(pd.get_dummies(PH_data.race_new, prefix='race_new', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(PH_data.esrd_cause, prefix='esrd_cause', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(PH_data.network_us_region_dfr, prefix='network_us_region_dfr', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(pd.Categorical(PH_data.chain_class2, [6,5,2,1,3,4], True), prefix='chain_class2', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(PH_data.profit_txc, prefix='profit_txc', drop_first=True))\n",
        "PH_data = PH_data.join(pd.get_dummies(PH_data.profit_hosp, prefix='profit_hosp', drop_first=True))\n",
        "PH_data = PH_data.drop(['dialysis_mod1', 'esrd_cause', 'age_cat', 'race_new', 'chain_class2', 'insurance_esrd', 'network_us_region_dfr', 'profit_txc', 'profit_hosp'], axis=1)\n",
        "\n",
        "# ideal cohort\n",
        "ideal = d[(d.INC_AGE < 66) &\n",
        "  (d.pvasc_new == 0) &\n",
        "  (d.chf == 0) &\n",
        "  (d.cva_new == 0) &\n",
        "  (d.PATTXOP_MEDUNFITn == 0)].reset_index(drop=True)\n",
        "\n",
        "PH_data_ideal = ideal[['PROVUSRD', 'chain_class2', 'for_profit', 'sex_new', 'age_cat', 'race_new', 'dialysis_mod1', 'esrd_cause', 'bmi_35',\n",
        "                 'ashd_new', 'chf',\t'other_cardiac', 'cva_new',\t'pvasc_new', 'hypertension', 'diabetes', 'copd_new',\n",
        "                 'smoke_new', 'cancer_new', 'insurance_esrd', 'PATTXOP_MEDUNFITn','nephcare_cat2',\n",
        "                 'network_us_region_dfr', 'NEAR_DIST', 'rucc_rural', 'wl', 'wl_time', 'livingd', 'ld_time', 'deceasedt', 'dec_time']]\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(PH_data_ideal.dialysis_mod1, prefix='dialysis_mod1', drop_first=True))\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(pd.Categorical(PH_data_ideal.insurance_esrd, [3, 2, 1, 4, 5], True), prefix='insurance_esrd', drop_first=True))\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(pd.Categorical(PH_data_ideal.age_cat, [5, 1, 2, 3, 4], True), prefix='age_cat', drop_first=True)) # delete category \"6\" for ideal cohort!\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(PH_data_ideal.race_new, prefix='race_new', drop_first=True))\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(PH_data_ideal.esrd_cause, prefix='esrd_cause', drop_first=True))\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(PH_data_ideal.network_us_region_dfr, prefix='network_us_region_dfr', drop_first=True))\n",
        "PH_data_ideal = PH_data_ideal.join(pd.get_dummies(pd.Categorical(PH_data_ideal.chain_class2, [6,5,2,1,3,4], True), prefix='chain_class2', drop_first=True))\n",
        "PH_data_ideal = PH_data_ideal.drop(['dialysis_mod1', 'esrd_cause', 'age_cat', 'race_new', 'chain_class2', 'insurance_esrd', 'network_us_region_dfr'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB6CFrA97xBB",
        "colab_type": "text"
      },
      "source": [
        "**Table 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37nzVT8M4LlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "varlist=['age_cat',\n",
        " 'sex_new',\n",
        " 'race_new',\n",
        " 'insurance_esrd',\n",
        " 'esrd_cause',\n",
        " 'dialysis_mod1',\n",
        " 'bmi_35',\n",
        " 'chf',\n",
        " 'ashd_new',\n",
        " 'other_cardiac',\n",
        " 'cva_new',\n",
        " 'pvasc_new',\n",
        " 'hypertension',\n",
        " 'diabetes',\n",
        " 'copd_new',\n",
        " 'smoke_new',\n",
        " 'cancer_new',\n",
        " 'nephcare_cat2',\n",
        " 'PATTXOP_MEDUNFITn',\n",
        " 'network_us_region_dfr',\n",
        " 'rucc_rural',\n",
        " 'NEAR_DIST']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wta3yOHCcqQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cph = CoxPHFitter()\n",
        "for time, status in zip(['wl_time', 'ld_time', 'dec_time'], ['wl', 'livingd', 'deceasedt']):\n",
        "  print('-'*30, status,'-'*30)\n",
        "  for exposure in varlist:\n",
        "    crude = '|'.join([exposure, time, status])\n",
        "    cph.fit(PH_data.filter(regex=crude), duration_col=time, event_col=status, step_size=0.5)\n",
        "    print(round(pd.concat([exp(cph.hazards_).rename('HR'), exp(cph.confidence_intervals_)], 1), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2qZ88uOcsqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for case, time in zip(['wl', 'livingd', 'deceasedt'], ['wl_time', 'ld_time', 'dec_time']):\n",
        "  tmp = d\n",
        "  count = tmp.groupby('chain_class2')[case].sum().map('{:,}'.format)\n",
        "  pyr = (tmp.groupby('chain_class2')[time].sum()/12).map(' /{:,.0f}'.format)\n",
        "  print(count+pyr)\n",
        "  count1 = tmp.groupby('for_profit')[case].sum().map('{:,}'.format)\n",
        "  pyr1 = (tmp.groupby('for_profit')[time].sum()/12).map(' /{:,.0f}'.format)\n",
        "  print(count1+pyr1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAntlnIGtNOS",
        "colab_type": "text"
      },
      "source": [
        "**Table 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4xX5BLtPC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cph = CoxPHFitter()\n",
        "for time, status in zip(['wl_time', 'ld_time', 'dec_time'], ['wl', 'livingd', 'deceasedt']):\n",
        "  print('-'*30, status,'-'*30)\n",
        "  for exposure in ['chain', 'for_profit']:\n",
        "    crude = '|'.join([exposure, time, status])\n",
        "    model1 = crude + '|sex_new|age_cat|race_new'\n",
        "    model2 = model1 + '|dialysis_mod1|esrd_cause|bmi_35|ashd_new|other_cardiac|hypertension|diabetes|'\\\n",
        "                  'copd_new|smoke_new|cancer_new'#chf|cva_new|pvasc_new'\n",
        "    model3 = model2 + '|insurance_esrd|network_us_region_dfr|NEAR_DIST|rucc_rural|PATTXOP_MEDUNFITn' #PATTXOP_MEDUNFITn'\n",
        "    for i, model in enumerate([crude, model1, model2, model3]):\n",
        "      print('\\n', 'model_'+str(i))\n",
        "      cph.fit(PH_data.filter(regex=model), duration_col=time, event_col=status, step_size=0.5)\n",
        "      print(round(pd.concat([exp(cph.hazards_[cph.hazards_.index.str.contains(exposure)]).rename('HR'), exp(cph.confidence_intervals_[cph.confidence_intervals_.index.str.contains(exposure)])], 1), 2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6qlhN9rpiS6",
        "colab_type": "text"
      },
      "source": [
        "**Figure 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rm85ojhpkBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d['FIRST_SE'] = pd.to_datetime(d['FIRST_SE'], format='%m/%d/%Y')\n",
        "fig2 = pd.DataFrame()\n",
        "\n",
        "for event, time in zip(['wl', 'livingd', 'deceasedt'], ['wl_time', 'ld_time', 'dec_time']):\n",
        "  print('-'*40, event, '-'*40)\n",
        "  for exposure in ['chain_class2', 'for_profit']:\n",
        "    print('\\n', exposure)\n",
        "    fig2 = pd.DataFrame()\n",
        "    for year in range(2001, 2016, 2):\n",
        "        num = d[(d['FIRST_SE']>=str(year)+'/01/01') & (d['FIRST_SE']<=str(year+1)+'/12/31')].groupby(exposure)[event].sum()\n",
        "        pyr = d[(d['FIRST_SE']>=str(year)+'/01/01') & (d['FIRST_SE']<=str(year+1)+'/12/31')].groupby(exposure)[time].sum()/12\n",
        "        rate = (num/pyr*100).rename(str(year)+'-'+\"{0:0>2}\".format(year+1-2000))\n",
        "        fig2 = pd.concat([fig2, rate], 1)\n",
        "    print(fig2.applymap('{:.2f}'.format))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK0npP4OyYr3",
        "colab_type": "text"
      },
      "source": [
        "**Supplemental Table 3 (ideal cohort)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-5KBzam78CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cph = CoxPHFitter()\n",
        "for time, status in zip(['wl_time', 'ld_time', 'dec_time'], ['wl', 'livingd', 'deceasedt']):\n",
        "  print('-'*30, status,'-'*30)\n",
        "  for exposure in ['chain', 'for_profit']:\n",
        "    crude = '|'.join([exposure, time, status])\n",
        "    model1 = crude + '|sex_new|age_cat|race_new'\n",
        "    model2 = model1 + '|dialysis_mod1|esrd_cause|bmi_35|ashd_new|other_cardiac|hypertension|diabetes|'\\\n",
        "                  'copd_new|smoke_new|cancer_new'#chf|cva_new|pvasc_new'\n",
        "    model3 = model2 + '|insurance_esrd|network_us_region_dfr|NEAR_DIST|rucc_rural' #PATTXOP_MEDUNFITn'\n",
        "    for i, model in enumerate([crude, model1, model2, model3]):\n",
        "      print('\\n', 'model'+str(i))\n",
        "      cph.fit(PH_data_ideal.filter(regex=model), duration_col=time, event_col=status, step_size=0.5)\n",
        "      print(round(pd.concat([exp(cph.hazards_[cph.hazards_.index.str.contains(exposure)]).rename('HR'), exp(cph.confidence_intervals_[cph.confidence_intervals_.index.str.contains(exposure)])], 1), 2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvVn3CKGIyg4",
        "colab_type": "text"
      },
      "source": [
        "**Supplemental Table 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHmcvFo0JQWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for time, status in zip(['wl_time', 'ld_time', 'dec_time'], ['wl', 'livingd', 'deceasedt']):\n",
        "  print('-'*30, status,'-'*30)\n",
        "  for r, region in enumerate(['Northeast', 'South', 'Midwest', 'West']):\n",
        "    print('\\n', region)\n",
        "    for exposure in ['chain', 'for_profit']:\n",
        "      crude = '|'.join([exposure, time, status])\n",
        "      model1 = crude + '|sex_new|age_cat|race_new'\n",
        "      model2 = model1 + '|dialysis_mod1|esrd_cause|bmi_35|ashd_new|other_cardiac|hypertension|diabetes|'\\\n",
        "                        'copd_new|smoke_new|cancer_new|chf|cva_new|pvasc_new'#chf|cva_new|pvasc_new'\n",
        "      model3 = model2 + '|insurance_esrd|NEAR_DIST|rucc_rural|PATTXOP_MEDUNFITn' #network_us_region_dfr'\n",
        "      cph.fit(PH_data[d['network_us_region_dfr']==r].filter(regex=model3), duration_col=time, event_col=status, step_size=0.5)\n",
        "      print(round(pd.concat([exp(cph.hazards_[cph.hazards_.index.str.contains(exposure)]).rename('HR'), exp(cph.confidence_intervals_[cph.confidence_intervals_.index.str.contains(exposure)])], 1), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz7Pt-3z3orc",
        "colab_type": "text"
      },
      "source": [
        "Supplemental Table 5 & 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nS2TD4Y3m8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cph = CoxPHFitter()\n",
        "for time, status in zip(['wl_time', 'ld_time', 'dec_time'], ['wl', 'livingd', 'deceasedt']):\n",
        "  print('-'*30, status,'-'*30)\n",
        "  for exposure in ['profit_txc', 'profit_hosp']:\n",
        "    crude = '|'.join([exposure, time, status])\n",
        "    model1 = crude + '|sex_new|age_cat|race_new'\n",
        "    model2 = model1 + '|dialysis_mod1|esrd_cause|bmi_35|ashd_new|other_cardiac|hypertension|diabetes|'\\\n",
        "                      'copd_new|smoke_new|cancer_new|chf|cva_new|pvasc_new'#chf|cva_new|pvasc_new'\n",
        "    model3 = model2 + '|insurance_esrd|NEAR_DIST|rucc_rural|PATTXOP_MEDUNFITn|network_us_region_dfr' #network_us_region_dfr'\n",
        "    for i, model in enumerate([crude, model1, model2, model3]):\n",
        "      print('\\n', 'model_'+str(i))\n",
        "      cph.fit(PH_data.filter(regex=model), duration_col=time, event_col=status, step_size=0.2)\n",
        "      print(round(pd.concat([exp(cph.hazards_[cph.hazards_.index.str.contains(exposure)]).rename('HR'), exp(cph.confidence_intervals_[cph.confidence_intervals_.index.str.contains(exposure)])], 1), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}